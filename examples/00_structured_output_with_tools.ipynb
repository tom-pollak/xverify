{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Output with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from xverify import ToolUse, run_tools, Env\n",
    "from xverify.tools import calculator, search\n",
    "from pydantic import ValidationError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Often when running multi-step reasoning, we want to use tools to help us.\n",
    "\n",
    "However, not many libraries natively support this. Pydantic for instance is optimized for a static declarative schema, which isn't well suited to ad-hoc tool use.\n",
    "\n",
    "Here we can see two examples of tools:\n",
    "- `calculator`: essentially a wrapper around the `eval` function\n",
    "- `search`: uses duckduckgo to search the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculator(expression='3 + 4 * (6 ** 7)')='1119747'\n",
      "\n",
      "---\n",
      "\n",
      "search(query='What is the capital of France?', num_results=1)='• Paris - Wikipedia\\n  Paris is a global city of culture, finance, diplomacy, and tourism, with an estimated population of 2 million residents in 2025.'\n"
     ]
    }
   ],
   "source": [
    "print(f\"{calculator(expression='3 + 4 * (6 ** 7)')=}\")\n",
    "print(\"\\n---\\n\")\n",
    "print(f\"{search(query='What is the capital of France?', num_results=1)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is we can't (natively) include a tool call in a Pydantic model (due to the static declarative schema).\n",
    "\n",
    "However, we can use the new `ToolUse` class to handle tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning=\"Let's add two numbers\" tool_use=calculator(expression='2 + 2', tool_name='calculator')\n",
      "calc_2_2.tool_use.run_tool()='4'\n"
     ]
    }
   ],
   "source": [
    "class ReasoiningTool(BaseModel):\n",
    "    \"\"\"The result of a reasoning tool\"\"\"\n",
    "\n",
    "    reasoning: str\n",
    "    tool_use: ToolUse[calculator, search]\n",
    "\n",
    "\n",
    "calc_2_2 = ReasoiningTool.model_validate(\n",
    "    {\n",
    "        \"reasoning\": \"Let's add two numbers\",\n",
    "        \"tool_use\": {\"tool_name\": \"calculator\", \"expression\": \"2 + 2\"},\n",
    "    }\n",
    ")\n",
    "print(calc_2_2)\n",
    "print(f\"{calc_2_2.tool_use.run_tool()=}\") # on a ToolUse object, we can call run_tool() to run the tool and get the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nice because if we can easily validate any arbitary schema and tool use is correct without any ad-hoc parsing (and we'll be able to enforce the LLM output is correct with guided decoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool not found!\n",
      "wrong argument!\n",
      "wrong argument type!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ReasoiningTool.model_validate(\n",
    "        {\n",
    "            \"reasoning\": \"\",\n",
    "            \"tool_use\": {\"tool_name\": \"none_existing_tool\", \"expression\": \"2 + 2\"},\n",
    "        }\n",
    "    )\n",
    "except ValidationError:\n",
    "    print(\"tool not found!\")\n",
    "try:\n",
    "    ReasoiningTool.model_validate(\n",
    "        {\n",
    "            \"reasoning\": \"\",\n",
    "            \"tool_use\": {\"tool_name\": \"calculator\", \"wrong_arg\": \"2 + 2\"},\n",
    "        },\n",
    "    )\n",
    "except ValidationError:\n",
    "    print(\"wrong argument!\")\n",
    "\n",
    "try:\n",
    "    ReasoiningTool.model_validate(\n",
    "        {\n",
    "            \"reasoning\": \"\",\n",
    "            \"tool_use\": {\"tool_name\": \"calculator\", \"expression\": 2 + 2},\n",
    "        },\n",
    "    )\n",
    "except ValidationError:\n",
    "    print(\"wrong argument type!\")\n",
    "\n",
    "try:\n",
    "    # TODO: this should be a validation error\n",
    "    ReasoiningTool.model_validate(\n",
    "        {\n",
    "            \"reasoning\": \"\",\n",
    "            \"tool_use\": {\"tool_name\": \"calculator\", \"expression\": \"2 + 2\", \"extra_arg\": \"extra_arg\"},\n",
    "        },\n",
    "    )\n",
    "except ValidationError:\n",
    "    print(\"extra argument!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement a ReACT loop with tools really easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reason_and_Act(scratchpad='the question is 2 + 2', reasoning='we should use the calculator tool!', output=Tools(action='tool_use', tool_use=calculator(expression='2 + 2', tool_name='calculator')))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from typing import Literal, Union\n",
    "\n",
    "class Tools(BaseModel):\n",
    "    \"\"\"\n",
    "    Run a tool.\n",
    "    \"\"\"\n",
    "    action: Literal[\"tool_use\"] = Field(..., description=\"Action discriminator\")\n",
    "    tool_use: ToolUse[calculator, search] = Field(..., description=\"The tool call to use\")\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    \"\"\"\n",
    "    Return a final answer.\n",
    "    \"\"\"\n",
    "    action: Literal[\"final_answer\"] = Field(..., description=\"Action discriminator\")\n",
    "    answer: str = Field(..., description=\"The final answer to the question\")\n",
    "\n",
    "class Reason_and_Act(BaseModel):\n",
    "    scratchpad: str = Field(..., description=\"Information from the Observation useful to answer the question\")\n",
    "    reasoning: str = Field(..., description=\"It describes your thoughts about the question you have been asked\")\n",
    "    output: Union[Tools, FinalAnswer] = Field(..., description=\"Final output: choose between the tool call or the final answer\", discriminator=\"action\")\n",
    "\n",
    "\n",
    "res = Reason_and_Act.model_validate(\n",
    "    {\n",
    "        \"scratchpad\": \"the question is 2 + 2\",\n",
    "        \"reasoning\": \"we should use the calculator tool!\",\n",
    "        \"output\": {\n",
    "            \"action\": \"tool_use\",\n",
    "            \"tool_use\": {\n",
    "                \"tool_name\": \"calculator\",\n",
    "                \"expression\": \"2 + 2\",\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in case we just want to run all the tools in a response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': {'tool_use': {'calculator': '4'}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_tools(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return `None` where no tools were called, which is useful for checking for the end of the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(run_tools(Reason_and_Act(scratchpad=\"\", reasoning=\"\", output=FinalAnswer(action=\"final_answer\", answer=\"42\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you just want the output, run `run_tools` on the instantiated `ToolUse` object itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res.output.tool_use.run_tool()='4'\n"
     ]
    }
   ],
   "source": [
    "if isinstance(res.output, Tools):\n",
    "    print(f\"{res.output.tool_use.run_tool()=}\")\n",
    "else:\n",
    "    print(f\"{res.output.answer=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we can do multiple tool calls in a single response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tool_use': [{'calculator': '4'},\n",
      "              {'search': '• Moon Fact Sheet - NSSDCA\\n'\n",
      "                         '  Equatorial radius (km) 1738.1: 6378.1: 0.2725: '\n",
      "                         'Polar radius (km) 1736.0: 6356.8: 0.2731: Volumetric '\n",
      "                         'mean radius (km) 1737.4: 6371.0: 0.2727: Ellipticity '\n",
      "                         '(Flattening) ...\\n'\n",
      "                         '\\n'\n",
      "                         '• Moon - Wikipedia\\n'\n",
      "                         '  The Moon has a solid iron-rich inner core with a '\n",
      "                         'radius possibly as small as 240 kilometres (150 mi) '\n",
      "                         'and a fluid outer core primarily made of liquid iron '\n",
      "                         'with a radius of roughly 300 kilometres (190 m.'},\n",
      "              {'calculator': '1480647168'}]}\n"
     ]
    }
   ],
   "source": [
    "class MultiToolUse(BaseModel):\n",
    "    tool_use: list[ToolUse[calculator, search]]\n",
    "\n",
    "\n",
    "res = MultiToolUse.model_validate(\n",
    "    {\n",
    "        \"tool_use\": [\n",
    "            {\"tool_name\": \"calculator\", \"expression\": \"2 + 2\"},\n",
    "            {\n",
    "                \"tool_name\": \"search\",\n",
    "                \"query\": \"What is the radius of the moon?\",\n",
    "                \"num_results\": 2,\n",
    "            },\n",
    "            {\"tool_name\": \"calculator\", \"expression\": \"3424 * 432432\"},\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "pprint(run_tools(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is cool, kinda, but now we have structed schema, we can **enforce** the LLM output is correct with guided decoding.\n",
    "\n",
    "Let's go back to our ReACT loop, and use `Env` to enforce the tool calls are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You are a helpful assistant, responding via JSON structured output. Tool responses from the user are also in JSON.\\n- Think step by step using the scratchpad, reasoning outputs. You have 4 steps to think before responding.\\n- Use the tools provided. DO NOT rely on your own knowledge when a tool is available to help you.\\n- Respond with a final answer once your are sure you have the answer.\\n\\nRespond with a JSON object, following the schema below:\\n\\n{\\n  \\\"$defs\\\": {\\n    \\\"FinalAnswer\\\": {\\n      \\\"properties\\\": {\\n        \\\"action\\\": {\\n          \\\"const\\\": \\\"final_answer\\\",\\n          \\\"title\\\": \\\"Action\\\",\\n          \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"answer\\\": {\\n          \\\"description\\\": \\\"The final answer to the question\\\",\\n          \\\"title\\\": \\\"Answer\\\",\\n          \\\"type\\\": \\\"string\\\"\\n        }\\n      },\\n      \\\"required\\\": [\\n        \\\"action\\\",\\n        \\\"answer\\\"\\n      ],\\n      \\\"title\\\": \\\"FinalAnswer\\\",\\n      \\\"type\\\": \\\"object\\\"\\n    },\\n    \\\"Tools\\\": {\\n      \\\"properties\\\": {\\n        \\\"action\\\": {\\n          \\\"const\\\": \\\"tool_use\\\",\\n          \\\"title\\\": \\\"Action\\\",\\n          \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"tool_use\\\": {\\n          \\\"description\\\": \\\"The tool call to use\\\",\\n          \\\"discriminator\\\": {\\n            \\\"mapping\\\": {\\n              \\\"calculator\\\": \\\"#/$defs/calculator\\\",\\n              \\\"search\\\": \\\"#/$defs/search\\\"\\n            },\\n            \\\"propertyName\\\": \\\"tool_name\\\"\\n          },\\n          \\\"oneOf\\\": [\\n            {\\n              \\\"$ref\\\": \\\"#/$defs/calculator\\\"\\n            },\\n            {\\n              \\\"$ref\\\": \\\"#/$defs/search\\\"\\n            }\\n          ],\\n          \\\"title\\\": \\\"Tool Use\\\"\\n        }\\n      },\\n      \\\"required\\\": [\\n        \\\"action\\\",\\n        \\\"tool_use\\\"\\n      ],\\n      \\\"title\\\": \\\"Tools\\\",\\n      \\\"type\\\": \\\"object\\\"\\n    },\\n    \\\"calculator\\\": {\\n      \\\"description\\\": \\\"Evaluates a single line of Python math expression. No imports or variables allowed.\\\\n\\\\n    Examples:\\\\n        {\\\\\\\"expression\\\\\\\": \\\\\\\"2 + 2\\\\\\\"} -> \\\\\\\"4\\\\\\\"\\\\n        {\\\\\\\"expression\\\\\\\": \\\\\\\"3 * (17 + 4)\\\\\\\"} -> \\\\\\\"63\\\\\\\"\\\\n        {\\\\\\\"expression\\\\\\\": \\\\\\\"100 / 5\\\\\\\"} -> \\\\\\\"20.0\\\\\\\"\\\\n    \\\\nReturns: str - The result of the calculation or an error message\\\",\\n      \\\"properties\\\": {\\n        \\\"expression\\\": {\\n          \\\"description\\\": \\\"A mathematical expression using only numbers and basic operators (+,-,*,/,**,())\\\",\\n          \\\"title\\\": \\\"Expression\\\",\\n          \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"tool_name\\\": {\\n          \\\"const\\\": \\\"calculator\\\",\\n          \\\"description\\\": \\\"Function to call\\\",\\n          \\\"title\\\": \\\"Tool Name\\\",\\n          \\\"type\\\": \\\"string\\\"\\n        }\\n      },\\n      \\\"required\\\": [\\n        \\\"expression\\\",\\n        \\\"tool_name\\\"\\n      ],\\n      \\\"title\\\": \\\"calculator\\\",\\n      \\\"type\\\": \\\"object\\\"\\n    },\\n    \\\"search\\\": {\\n      \\\"description\\\": \\\"Searches DuckDuckGo and returns concise summaries of top results.\\\\n\\\\n    Examples:\\\\n        {\\\\\\\"query\\\\\\\": \\\\\\\"who invented the lightbulb\\\\\\\", \\\\\\\"num_results\\\\\\\": 3}\\\\n    \\\\nReturns: str - Formatted string with bullet points of top results, each with title and brief summary\\\",\\n      \\\"properties\\\": {\\n        \\\"query\\\": {\\n          \\\"description\\\": \\\"The search query string\\\",\\n          \\\"title\\\": \\\"Query\\\",\\n          \\\"type\\\": \\\"string\\\"\\n        },\\n        \\\"num_results\\\": {\\n          \\\"default\\\": 5,\\n          \\\"description\\\": \\\"Number of results to return (default: 5, max: 10)\\\",\\n          \\\"title\\\": \\\"Num Results\\\",\\n          \\\"type\\\": \\\"integer\\\"\\n        },\\n        \\\"tool_name\\\": {\\n          \\\"const\\\": \\\"search\\\",\\n          \\\"description\\\": \\\"Function to call\\\",\\n          \\\"title\\\": \\\"Tool Name\\\",\\n          \\\"type\\\": \\\"string\\\"\\n        }\\n      },\\n      \\\"required\\\": [\\n        \\\"query\\\",\\n        \\\"tool_name\\\"\\n      ],\\n      \\\"title\\\": \\\"search\\\",\\n      \\\"type\\\": \\\"object\\\"\\n    }\\n  },\\n  \\\"properties\\\": {\\n    \\\"scratchpad\\\": {\\n      \\\"description\\\": \\\"Information from the Observation useful to answer the question\\\",\\n      \\\"title\\\": \\\"Scratchpad\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"reasoning\\\": {\\n      \\\"description\\\": \\\"It describes your thoughts about the question you have been asked\\\",\\n      \\\"title\\\": \\\"Reasoning\\\",\\n      \\\"type\\\": \\\"string\\\"\\n    },\\n    \\\"output\\\": {\\n      \\\"description\\\": \\\"Final output: choose between the tool call or the final answer\\\",\\n      \\\"discriminator\\\": {\\n        \\\"mapping\\\": {\\n          \\\"final_answer\\\": \\\"#/$defs/FinalAnswer\\\",\\n          \\\"tool_use\\\": \\\"#/$defs/Tools\\\"\\n        },\\n        \\\"propertyName\\\": \\\"action\\\"\\n      },\\n      \\\"oneOf\\\": [\\n        {\\n          \\\"$ref\\\": \\\"#/$defs/Tools\\\"\\n        },\\n        {\\n          \\\"$ref\\\": \\\"#/$defs/FinalAnswer\\\"\\n        }\\n      ],\\n      \\\"title\\\": \\\"Output\\\"\\n    }\\n  },\\n  \\\"required\\\": [\\n    \\\"scratchpad\\\",\\n    \\\"reasoning\\\",\\n    \\\"output\\\"\\n  ],\\n  \\\"title\\\": \\\"Reason_and_Act\\\",\\n  \\\"type\\\": \\\"object\\\"\\n}\\n\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"What is the radius of the moon?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": {\n",
      "      \"scratchpad\": \"The radius of the moon is approximately 2, 380 km.\",\n",
      "      \"reasoning\": \"The radius of the moon is a well-known scientific fact, based on observations and measurements.\",\n",
      "      \"output\": {\n",
      "        \"action\": \"final_answer\",\n",
      "        \"answer\": \"The radius of the moon is approximately 2, 380 km.\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM\n",
    "\n",
    "if \"llm\" not in globals():  # interactive use\n",
    "    llm = LLM(model=\"Qwen/Qwen2.5-0.5B-Instruct\", max_model_len=2000)\n",
    "\n",
    "env = Env(Reason_and_Act)\n",
    "sampling_params = env.sampling_params(\n",
    "    max_tokens=500,\n",
    "    guided_decoding=dict(whitespace_pattern=r\"[\\n ]?\"),\n",
    "    n=1,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "max_steps = 5\n",
    "messages: list[dict] = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"\\\n",
    "You are a helpful assistant, responding via JSON structured output. Tool responses from the user are also in JSON.\n",
    "- Think step by step using the scratchpad, reasoning outputs. You have {max_steps - 1} steps to think before responding.\n",
    "- Use the tools provided. DO NOT rely on your own knowledge when a tool is available to help you.\n",
    "- Respond with a final answer once your are sure you have the answer.\n",
    "\n",
    "Respond with a JSON object, following the schema below:\n",
    "\n",
    "{json.dumps(env.model.model_json_schema(), indent=2)}\n",
    "\n",
    "\"\"\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"What is the radius of the moon?\"},\n",
    "]\n",
    "\n",
    "for _ in range(max_steps):\n",
    "    outp = llm.chat(  # type: ignore\n",
    "        messages=messages,  # type: ignore\n",
    "        sampling_params=sampling_params,\n",
    "        use_tqdm=False,\n",
    "    )\n",
    "    struct_res = env.parse(outp[0].outputs[0].text)\n",
    "    messages.append({\"role\": \"assistant\", \"content\": struct_res.model_dump()})\n",
    "    tool_outp = run_tools(struct_res)\n",
    "    if tool_outp:\n",
    "        messages.append({\"role\": \"user\", \"content\": tool_outp})\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(json.dumps(messages, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Reason_and_Act"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root ::= (\" \"| \"\\n\") grammar-models\n",
      "grammar-models ::= reason-and--act\n",
      "reason-and--act ::= \"{\" \"\\n\"  ws \"\\\"scratchpad\\\"\" \":\" ws string \",\" \"\\n\"  ws \"\\\"reasoning\\\"\" \":\" ws string \",\" \"\\n\"  ws \"\\\"output\\\"\" \":\" ws reason-and--act-output-union \"\\n\" ws \"}\"\n",
      "tools ::= \"{\" \"\\n\"  ws \"\\\"action\\\"\" \":\" ws unknown \",\" \"\\n\"  ws \"\\\"tool_use\\\"\" \":\" ws unknown \"\\n\" ws \"}\"\n",
      "final-answer ::= \"{\" \"\\n\"  ws \"\\\"action\\\"\" \":\" ws unknown \",\" \"\\n\"  ws \"\\\"answer\\\"\" \":\" ws string \"\\n\" ws \"}\"\n",
      "reason-and--act-output-union ::= tools | final-answer\n",
      "boolean ::= \"true\" | \"false\"\n",
      "null ::= \"null\"\n",
      "string ::= \"\\\"\" (\n",
      "        [^\"\\\\] |\n",
      "        \"\\\\\" ([\"\\\\/bfnrt] | \"u\" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F])\n",
      "      )* \"\\\"\" ws\n",
      "ws ::= ([ \\t\\n] ws)?\n",
      "float ::= (\"-\"? ([0-9] | [1-9] [0-9]*)) (\".\" [0-9]+)? ([eE] [-+]? [0-9]+)? ws\n",
      "integer ::= [0-9]+\n",
      "--------------------------------------------------------------------------------\n",
      "Output Model: Reason_and_Act\n",
      "  Output Fields:\n",
      "    scratchpad (str):\n",
      "        Description: Information from the Observation useful to answer the question\n",
      "    reasoning (str):\n",
      "        Description: It describes your thoughts about the question you have been asked\n",
      "    output (tools or final-answer):\n",
      "        Description: Final output: choose between the tool call or the final answer\n",
      "\n",
      "Model: Tools\n",
      "  Description: Run a tool.\n",
      "  Fields:\n",
      "    action (literal):\n",
      "        Description: Action discriminator\n",
      "    tool_use (annotated):\n",
      "        Description: The tool call to use\n",
      "\n",
      "Model: FinalAnswer\n",
      "  Description: Return a final answer.\n",
      "  Fields:\n",
      "    action (literal):\n",
      "        Description: Action discriminator\n",
      "    answer (str):\n",
      "        Description: The final answer to the question\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic_gbnf_grammar_generator import generate_gbnf_grammar_and_documentation\n",
    "\n",
    "gbnf_grammar, documentation = generate_gbnf_grammar_and_documentation(\n",
    "    [Reason_and_Act],\n",
    "    # outer_object_name=\"Reason_and_Act\",\n",
    "    documentation_with_field_description=True,\n",
    ")\n",
    "\n",
    "\n",
    "print(gbnf_grammar)\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Model: calculator\n",
      "  Description: Evaluates a single line of Python math expression. No imports or variables allowed.\n",
      "\n",
      "    Examples:\n",
      "        {\"expression\": \"2 + 2\"} -> \"4\"\n",
      "        {\"expression\": \"3 * (17 + 4)\"} -> \"63\"\n",
      "        {\"expression\": \"100 / 5\"} -> \"20.0\"\n",
      "    \n",
      "Returns: str - The result of the calculation or an error message\n",
      "  Output Fields:\n",
      "    expression (str):\n",
      "        Description: A mathematical expression using only numbers and basic operators (+,-,*,/,**,())\n",
      "    tool_name (literal):\n",
      "        Description: Function to call\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbnf_grammar, documentation = generate_gbnf_grammar_and_documentation(\n",
    "    [ToolUse[calculator]],\n",
    ")\n",
    "\n",
    "print(documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the cool thing is, this is a Qwen 1.5B model, not even trained on function calling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root ::= (\" \"| \"\\n\") grammar-models\n",
      "grammar-models ::= reason-and--act\n",
      "reason-and--act ::= \"{\" \"\\n\"  ws \"\\\"scratchpad\\\"\" \":\" ws string \",\" \"\\n\"  ws \"\\\"reasoning\\\"\" \":\" ws string \",\" \"\\n\"  ws \"\\\"output\\\"\" \":\" ws reason-and--act-output-union \"\\n\" ws \"}\"\n",
      "tools ::= \"{\" \"\\n\"  ws \"\\\"action\\\"\" \":\" ws unknown \",\" \"\\n\"  ws \"\\\"tool_use\\\"\" \":\" ws calculator \"\\n\" ws \"}\"\n",
      "calculator ::= \"{\" \"\\n\"  ws \"\\\"expression\\\"\" \":\" ws string \",\" \"\\n\"  ws \"\\\"tool_name\\\"\" \":\" ws unknown \"\\n\" ws \"}\"\n",
      "final-answer ::= \"{\" \"\\n\"  ws \"\\\"action\\\"\" \":\" ws unknown \",\" \"\\n\"  ws \"\\\"answer\\\"\" \":\" ws string \"\\n\" ws \"}\"\n",
      "reason-and--act-output-union ::= tools | final-answer\n",
      "boolean ::= \"true\" | \"false\"\n",
      "null ::= \"null\"\n",
      "string ::= \"\\\"\" (\n",
      "        [^\"\\\\] |\n",
      "        \"\\\\\" ([\"\\\\/bfnrt] | \"u\" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F])\n",
      "      )* \"\\\"\" ws\n",
      "ws ::= ([ \\t\\n] ws)?\n",
      "float ::= (\"-\"? ([0-9] | [1-9] [0-9]*)) (\".\" [0-9]+)? ([eE] [-+]? [0-9]+)? ws\n",
      "integer ::= [0-9]+\n",
      "--------------------------------------------------------------------------------\n",
      "Output Model: Reason_and_Act\n",
      "  Output Fields:\n",
      "    scratchpad (str):\n",
      "        Description: Information from the Observation useful to answer the question\n",
      "    reasoning (str):\n",
      "        Description: It describes your thoughts about the question you have been asked\n",
      "    output (tools or final-answer):\n",
      "        Description: Final output: choose between the tool call or the final answer\n",
      "\n",
      "Model: Tools\n",
      "  Description: Run a tool.\n",
      "  Fields:\n",
      "    action (literal):\n",
      "        Description: Action discriminator\n",
      "    tool_use (calculator)\n",
      "      Details:\n",
      "            expression (str):\n",
      "        Description: A mathematical expression using only numbers and basic operators (+,-,*,/,**,())\n",
      "            tool_name (literal):\n",
      "        Description: Function to call\n",
      "\n",
      "Model: FinalAnswer\n",
      "  Description: Return a final answer.\n",
      "  Fields:\n",
      "    action (literal):\n",
      "        Description: Action discriminator\n",
      "    answer (str):\n",
      "        Description: The final answer to the question\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Tools(BaseModel):\n",
    "    \"\"\"\n",
    "    Run a tool.\n",
    "    \"\"\"\n",
    "    action: Literal[\"tool_use\"] = Field(..., description=\"Action discriminator\", json_schema_extra={\"example\": \"{'action': 'tool_use', 'tool_use': {'tool_name': 'calculator', 'expression': '2 + 2'}}\"})\n",
    "    tool_use: ToolUse[calculator]\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    \"\"\"\n",
    "    Return a final answer.\n",
    "    \"\"\"\n",
    "    action: Literal[\"final_answer\"] = Field(..., description=\"Action discriminator\")\n",
    "    answer: str = Field(..., description=\"The final answer to the question\")\n",
    "\n",
    "class Reason_and_Act(BaseModel):\n",
    "    scratchpad: str = Field(..., description=\"Information from the Observation useful to answer the question\")\n",
    "    reasoning: str = Field(..., description=\"It describes your thoughts about the question you have been asked\")\n",
    "    output: Union[Tools, FinalAnswer] = Field(..., description=\"Final output: choose between the tool call or the final answer\", discriminator=\"action\")\n",
    "\n",
    "from pydantic_gbnf_grammar_generator import generate_gbnf_grammar_and_documentation\n",
    "\n",
    "gbnf_grammar, documentation = generate_gbnf_grammar_and_documentation(\n",
    "    [Reason_and_Act],\n",
    "    # outer_object_name=\"Reason_and_Act\",\n",
    "    documentation_with_field_description=True,\n",
    ")\n",
    "\n",
    "\n",
    "print(gbnf_grammar)\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'FinalAnswer': {'description': 'Return a final answer.',\n",
       "   'properties': {'action': {'const': 'final_answer',\n",
       "     'description': 'Action discriminator',\n",
       "     'title': 'Action',\n",
       "     'type': 'string'},\n",
       "    'answer': {'description': 'The final answer to the question',\n",
       "     'title': 'Answer',\n",
       "     'type': 'string'}},\n",
       "   'required': ['action', 'answer'],\n",
       "   'title': 'FinalAnswer',\n",
       "   'type': 'object'},\n",
       "  'Tools': {'description': 'Run a tool.',\n",
       "   'properties': {'action': {'const': 'tool_use',\n",
       "     'description': 'Action discriminator',\n",
       "     'example': \"{'action': 'tool_use', 'tool_use': {'tool_name': 'calculator', 'expression': '2 + 2'}}\",\n",
       "     'title': 'Action',\n",
       "     'type': 'string'},\n",
       "    'tool_use': {'$ref': '#/$defs/calculator',\n",
       "     'description': 'The tool call to use'}},\n",
       "   'required': ['action', 'tool_use'],\n",
       "   'title': 'Tools',\n",
       "   'type': 'object'},\n",
       "  'calculator': {'description': 'Evaluates a single line of Python math expression. No imports or variables allowed.\\n\\n    Examples:\\n        {\"expression\": \"2 + 2\"} -> \"4\"\\n        {\"expression\": \"3 * (17 + 4)\"} -> \"63\"\\n        {\"expression\": \"100 / 5\"} -> \"20.0\"\\n    \\nReturns: str - The result of the calculation or an error message',\n",
       "   'properties': {'expression': {'description': 'A mathematical expression using only numbers and basic operators (+,-,*,/,**,())',\n",
       "     'title': 'Expression',\n",
       "     'type': 'string'},\n",
       "    'tool_name': {'const': 'calculator',\n",
       "     'description': 'Function to call',\n",
       "     'title': 'Tool Name',\n",
       "     'type': 'string'}},\n",
       "   'required': ['expression', 'tool_name'],\n",
       "   'title': 'calculator',\n",
       "   'type': 'object'}},\n",
       " 'properties': {'scratchpad': {'description': 'Information from the Observation useful to answer the question',\n",
       "   'title': 'Scratchpad',\n",
       "   'type': 'string'},\n",
       "  'reasoning': {'description': 'It describes your thoughts about the question you have been asked',\n",
       "   'title': 'Reasoning',\n",
       "   'type': 'string'},\n",
       "  'output': {'description': 'Final output: choose between the tool call or the final answer',\n",
       "   'discriminator': {'mapping': {'final_answer': '#/$defs/FinalAnswer',\n",
       "     'tool_use': '#/$defs/Tools'},\n",
       "    'propertyName': 'action'},\n",
       "   'oneOf': [{'$ref': '#/$defs/Tools'}, {'$ref': '#/$defs/FinalAnswer'}],\n",
       "   'title': 'Output'}},\n",
       " 'required': ['scratchpad', 'reasoning', 'output'],\n",
       " 'title': 'Reason_and_Act',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reason_and_Act.model_json_schema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
