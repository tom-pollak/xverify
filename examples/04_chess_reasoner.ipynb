{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-25 13:06:35 [__init__.py:256] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "import chess\n",
    "import chess.engine\n",
    "import chess.pgn\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from peft import LoraConfig  # type: ignore\n",
    "from pydantic import BaseModel, Field\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "import xverify as xv\n",
    "from xverify import GuidedSchema\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Can I push to HF\n",
    "if os.environ.get(\"HF_TOKEN\") is None:\n",
    "    raise ValueError(\"HF_TOKEN not found! Please set\")\n",
    "\n",
    "ENGINE = chess.engine.SimpleEngine.popen_uci(\"stockfish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== CONFIGURATION PARAMETERS ========\n",
    "# fmt: off\n",
    "NUM_SAMPLES = 1000\n",
    "\n",
    "# Reward function weights\n",
    "UCI_FORMAT_WEIGHT = 0.25         # Valid UCI notation\n",
    "LEGAL_MOVE_WEIGHT = 0.5          # Legal move\n",
    "MOVE_QUALITY_WEIGHT = 2.         # Good move quality\n",
    "\n",
    "# deduct points for repeating moves\n",
    "REPEAT_MOVE_PENALTY = 0.05\n",
    "MOVE_HISTORY = deque(maxlen=50)\n",
    "\n",
    "# Engine settings\n",
    "ENGINE_ANALYSIS_TIME = 1.5  # Time limit for engine analysis in seconds\n",
    "\n",
    "# fmt: on\n",
    "# =========================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given a chess position in FEN notation, analyze it and suggest the best move in UCI notation.\n",
      "\n",
      "Respond in the following format:\n",
      "\n",
      "Output Model: Chess_Reason_and_Act\n",
      "  Output Fields:\n",
      "    scratchpad (str):\n",
      "        Description: Information from the Observation useful to answer the question\n",
      "    reasoning (str):\n",
      "        Description: It describes your thoughts about the question you have been asked\n",
      "    best_move (str):\n",
      "        Description: The best move to make in the current position, in UCI notation (e.g. b7b3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Chess_Reason_and_Act(BaseModel):\n",
    "    scratchpad: str = Field(\n",
    "        ...,\n",
    "        description=\"Information from the Observation useful to answer the question\",\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        ...,\n",
    "        description=\"It describes your thoughts about the question you have been asked\",\n",
    "    )\n",
    "    best_move: str = Field(\n",
    "        ...,\n",
    "        description=\"The best move to make in the current position, in UCI notation (e.g. b7b3)\",\n",
    "    )\n",
    "\n",
    "\n",
    "guided_schema = GuidedSchema(Chess_Reason_and_Act)\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "Given a chess position in FEN notation, analyze it and suggest the best move in UCI notation.\n",
    "\n",
    "Respond in the following format:\n",
    "\n",
    "{guided_schema.doc}\n",
    "\"\"\"\n",
    "\n",
    "print(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(trajectory: list[dict[str, str]]) -> str:\n",
    "    \"\"\"Extract the last answer from a trajectory.\"\"\"\n",
    "    last_message = trajectory[-1]\n",
    "    assert last_message[\"role\"] == \"assistant\", \"should be assistant\"\n",
    "    parsed: Chess_Reason_and_Act | None = guided_schema.parse(last_message[\"content\"])  # type: ignore\n",
    "    return parsed.best_move if parsed else \"\"\n",
    "\n",
    "def extract_completions(completions) -> list[str]:\n",
    "    \"\"\"Extract the last answer from a trajectory.\"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    return [extract_answer(r) for r in responses]\n",
    "\n",
    "def is_valid_uci_format(move_str: str) -> bool:\n",
    "    \"\"\"Check if a string is in valid UCI move format (e.g., e2e4)\"\"\"\n",
    "    try:\n",
    "        chess.Move.from_uci(move_str)\n",
    "        return True\n",
    "    except:  # noqa: E722\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_legal_move(move_str: str, board: chess.Board) -> bool:\n",
    "    \"\"\"Check if a move string is valid for the given board position\"\"\"\n",
    "    try:\n",
    "        move = chess.Move.from_uci(move_str)\n",
    "        return move in board.legal_moves\n",
    "    except:  # noqa: E722\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def valid_uci_reward(completions, fen, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the move is a valid UCI format\"\"\"\n",
    "    extracted_moves = extract_completions(completions)\n",
    "\n",
    "    rewards = []\n",
    "    for i, move in enumerate(extracted_moves):\n",
    "        move = move.strip()\n",
    "        valid_uci = is_valid_uci_format(move)\n",
    "        rewards.append(UCI_FORMAT_WEIGHT if valid_uci else 0.0)\n",
    "\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def legal_move_reward(completions, fen, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the move is legal\"\"\"\n",
    "    extracted_moves = extract_completions(completions)\n",
    "\n",
    "    rewards = []\n",
    "    for i, move in enumerate(extracted_moves):\n",
    "        move = move.strip()\n",
    "        board = chess.Board(fen[i])\n",
    "\n",
    "        legal = is_legal_move(move, board)\n",
    "        if legal:\n",
    "            reward = LEGAL_MOVE_WEIGHT\n",
    "            frequency = MOVE_HISTORY.count(move)\n",
    "            frequency_penalty = frequency * REPEAT_MOVE_PENALTY\n",
    "            reward = max(0.0, reward * (1.0 - frequency_penalty))\n",
    "        else:\n",
    "            reward = 0.0\n",
    "\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def engine_analysis_reward(completions, fen, **kwargs) -> list[float]:\n",
    "    \"\"\"\n",
    "    Reward based on how good the suggested move is according to the engine.\n",
    "    Uses centipawn loss to evaluate move quality.\n",
    "    This is the final reward function, so it's responsible for calling the logging function.\n",
    "    \"\"\"\n",
    "    engine_time = 0.0\n",
    "    centipawn_losses = []\n",
    "\n",
    "    extracted_moves = extract_completions(completions)\n",
    "\n",
    "    move_rewards = []\n",
    "\n",
    "    for i, move in enumerate(extracted_moves):\n",
    "        move = move.strip()\n",
    "        board = chess.Board(fen[i])\n",
    "\n",
    "        # Skip evaluation for invalid moves\n",
    "        if not move or not is_valid_uci_format(move) or not is_legal_move(move, board):\n",
    "            move_rewards.append(0.0)\n",
    "            centipawn_losses.append(None)\n",
    "            continue\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # Engine analysis of current position\n",
    "        initial_eval = ENGINE.analyse(\n",
    "            board, chess.engine.Limit(time=ENGINE_ANALYSIS_TIME)\n",
    "        )\n",
    "        best_move = initial_eval[\"pv\"][0]\n",
    "        initial_score = initial_eval[\"score\"].relative.score(mate_score=10000)\n",
    "\n",
    "        # Make player's move and get new evaluation\n",
    "        player_move = chess.Move.from_uci(move)\n",
    "        board.push(player_move)\n",
    "        player_eval = ENGINE.analyse(\n",
    "            board, chess.engine.Limit(time=ENGINE_ANALYSIS_TIME)\n",
    "        )\n",
    "\n",
    "        # Negate because it's from opponent's perspective\n",
    "        after_move_score = -player_eval[\"score\"].relative.score(mate_score=10000)\n",
    "\n",
    "        # Calculate centipawn loss\n",
    "        centipawn_loss = initial_score - after_move_score\n",
    "\n",
    "        centipawn_losses.append(centipawn_loss)\n",
    "\n",
    "        # Reward scaling\n",
    "        # - Less than 300 (bishop / rook blunder) is 0.0\n",
    "        # - Best move is 1.0\n",
    "        reward = 0.0\n",
    "        if centipawn_loss <= 0:\n",
    "            reward = 1.0\n",
    "        elif centipawn_loss >= 300:\n",
    "            reward = 0.0\n",
    "        else:\n",
    "            reward = 1.0 - (centipawn_loss / 300.0)\n",
    "\n",
    "        move_rewards.append(reward * MOVE_QUALITY_WEIGHT)\n",
    "\n",
    "        engine_time += time.perf_counter() - start_time\n",
    "\n",
    "    wandb.log({\"train/engine_time\": engine_time})\n",
    "    wandb.log({\"train/centipawn_losses\": centipawn_losses})\n",
    "\n",
    "    return move_rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_random_position(row) -> str:\n",
    "    \"\"\"Extract a random position from a chess game\"\"\"\n",
    "    pgn = io.StringIO(row[\"text\"])\n",
    "    game = chess.pgn.read_game(pgn)\n",
    "    if not game:\n",
    "        return chess.STARTING_FEN\n",
    "\n",
    "    board = game.board()\n",
    "    mainline_moves = list(game.mainline_moves())\n",
    "    if not mainline_moves:\n",
    "        return chess.STARTING_FEN\n",
    "\n",
    "    # Choose a random point in the game (not too early, not too late)\n",
    "    min_move = min(5, len(mainline_moves) // 5)\n",
    "    max_move = max(min_move + 1, len(mainline_moves) - 5)\n",
    "    if max_move <= min_move:\n",
    "        max_move = min(len(mainline_moves), min_move + 10)\n",
    "\n",
    "    # Apply moves up to the random point\n",
    "    move_count = random.randint(min_move, max_move)\n",
    "    for move in mainline_moves[:move_count]:\n",
    "        board.push(move)\n",
    "\n",
    "    return board.fen()\n",
    "\n",
    "\n",
    "def format_dataset(row):\n",
    "    \"\"\"Format dataset for GRPO training\"\"\"\n",
    "    return {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Analyze this chess position and give the best move: {row['fen']}\",\n",
    "            },\n",
    "        ],\n",
    "        \"fen\": row[\"fen\"],\n",
    "    }\n",
    "\n",
    "dataset = load_dataset( # type: ignore\n",
    "    \"Icannos/lichess_games\",\n",
    "    streaming=True,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "positions = []\n",
    "for _, row in tqdm(\n",
    "    zip(range(NUM_SAMPLES), dataset[\"train\"]),\n",
    "    desc=\"Loading chess positions\",\n",
    "    total=NUM_SAMPLES,\n",
    "):\n",
    "    positions.append(get_random_position(row))\n",
    "\n",
    "dataset: Dataset = Dataset.from_dict({\"fen\": positions})\n",
    "dataset = dataset.map(format_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Liger kernel\n",
      "Applied Liger kernels to Qwen2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7338fd6b89494052a8ef4cc9fd73d802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_name = \"google/gemma-3-4b-it\"\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "lora_rank = 16\n",
    "lora_alpha = 64\n",
    "\n",
    "gpu_memory_utilization = 0.85\n",
    "\n",
    "model, tokenizer = xv.get_model_and_tokenizer(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    use_cache=False,\n",
    ")\n",
    "\n",
    "max_seq_length = 1280\n",
    "max_prompt_length = 256\n",
    "max_completion_length = max_seq_length - max_prompt_length\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=lora_rank,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=\"all-linear\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/fun/xverify/.venv/lib/python3.12/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/home/tom/fun/xverify/.venv/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = None  # No checkpoint: None\n",
    "\n",
    "training_args = xv.get_default_grpo_config(\n",
    "    \"chess-reasoner-training\",\n",
    "    learning_rate=5e-6,\n",
    "    weight_decay=0.1,\n",
    "    optim=\"adamw_8bit\",\n",
    "    per_device_train_batch_size=6,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_generations=6,\n",
    "    max_prompt_length=max_seq_length,\n",
    "    max_completion_length=max_completion_length,\n",
    "    max_steps=NUM_SAMPLES,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    max_grad_norm=0.1,\n",
    "    report_to=\"wandb\",\n",
    "    output_dir=\"outputs\",\n",
    "    vllm_gpu_memory_utilization=gpu_memory_utilization,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = xv.GRPOGuidedTrainer(\n",
    "    guided_schema=guided_schema,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    reward_funcs=[\n",
    "        legal_move_reward,\n",
    "        valid_uci_reward,\n",
    "        engine_analysis_reward,\n",
    "    ],\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=checkpoint_path)\n",
    "\n",
    "model.save_lora(\"chess_reasoner_llama_8b_lora\")\n",
    "print(\"Model saved to chess_reasoner_llama_8b_lora\")\n",
    "\n",
    "ENGINE.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_hub(model, tokenizer, repo_id):\n",
    "    \"\"\"Upload the trained model to Hugging Face Hub\"\"\"\n",
    "    tqdm.write(f\"Uploading model to Hugging Face Hub: {repo_id}\")\n",
    "    model.push_to_hub(repo_id)\n",
    "    tokenizer.push_to_hub(repo_id)\n",
    "    tqdm.write(f\"Successfully uploaded model to: https://huggingface.co/{repo_id}\")\n",
    "\n",
    "# push_to_hub(model, tokenizer, \"tommyp111/chess-reasoner\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
